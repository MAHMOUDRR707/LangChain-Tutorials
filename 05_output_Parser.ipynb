{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eu92YUgR0bNj",
        "outputId": "5f863fe0-bc2f-4b93-d071-179110bcb437"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q langchain==0.0.219 openai==0.27.8\n",
        "\n",
        "# !pip install -q transformers==4.29.2 sentencepiece==0.1.99 accelerate==0.19.0 bitsandbytes==0.39.0\n",
        "\n",
        "!pip install -q python-dotenv==1.0.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "from dotenv import dotenv_values\n",
        "load_dotenv =  dotenv_values(\"./app.env\")\n",
        "\n",
        "openai_api_key = load_dotenv[\"OPEN_API_KEY\"]\n"
      ],
      "metadata": {
        "id": "7-scmZzC0qMM"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(model_name=\"gpt-3.5-turbo\",openai_api_key=openai_api_key, temperature=0.9)"
      ],
      "metadata": {
        "id": "QK9l04Pn02aA"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Listing parsing"
      ],
      "metadata": {
        "id": "tB1FGcxP6VOH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
        "from langchain.prompts.prompt import PromptTemplate\n",
        "\n",
        "output_parser = CommaSeparatedListOutputParser()\n",
        "fromat_instructions = output_parser.get_format_instructions()\n",
        "print(fromat_instructions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ns0MSQoQ6UvX",
        "outputId": "7d8d8cd0-ff81-4f1c-f25a-c18824fe73f0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your response should be a list of comma separated values, eg: `foo, bar, baz`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = PromptTemplate(input_variables=[\"typee\"],\n",
        "                        template= \"I want to know ingradient of {typee} pasta.\\n{fromat_instructions}\",\n",
        "                        partial_variables={\"fromat_instructions\":fromat_instructions})\n",
        "\n",
        "print(prompt.format(typee=\"Egyptian\"))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4Hd6wqd1Mgl",
        "outputId": "05f2cf95-e9fa-446f-b876-cf069d7667d9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I want to know ingradient of Egyptian pasta.\n",
            "Your response should be a list of comma separated values, eg: `foo, bar, baz`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pro_prompt =  prompt.format(typee=\"Egyptian\")\n",
        "\n",
        "response = llm(pro_prompt)\n",
        "print(response)\n",
        "\n",
        "output = output_parser.parse(response)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3Mq--JI7e8L",
        "outputId": "0d6a2bde-5d05-4d57-8824-f7ef1c52d413"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "flour, water, salt\n",
            "['flour', 'water', 'salt']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DateTime Parsing"
      ],
      "metadata": {
        "id": "MzdLvJdk8uMR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "format_instructions = \"answer the question with datetime format like  03/05/2020 and location like London/England\"\n",
        "\n",
        "prompt =  PromptTemplate(template = \"When {name} who is famour born  and where ? \\n {format_instructions}\",\n",
        "                         input_variables =[\"name\"],\n",
        "                         partial_variables={\"format_instructions\":format_instructions})\n",
        "\n",
        "print(prompt.format(name=\"albert einstein\"))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bw5w2Qe18q5P",
        "outputId": "e5630534-8148-43ae-8f90-7a878a08488b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "When albert einstein who is famour born  and where ? \n",
            " answer the question with datetime format like  03/05/2020 and location like London/England\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pro_prompt =  prompt.format(name=\"albert einstein\")\n",
        "\n",
        "response = llm(pro_prompt)\n",
        "print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dI4VlwHR9efF",
        "outputId": "1b8eaa35-a85c-490e-cace-9f6da4b09976"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "03/14/1879 in Ulm, Germany\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pro_prompt =  prompt.format(name=\"Mahmoud Reda\")\n",
        "\n",
        "response = llm(pro_prompt)\n",
        "print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gqfuiT29krD",
        "outputId": "76af6163-f7c2-4fb8-bb9b-0845d0a995d0"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "09/01/1930 in Cairo, Egypt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PyDantic Parsing\n",
        "\n",
        "it is a format to return the parsing as class format so we can use it in other applications like fastApi for example"
      ],
      "metadata": {
        "id": "PkJYzobZ9uih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "from pydantic import BaseModel , Field\n",
        "from langchain.output_parsers import PydanticOutputParser\n",
        "from langchain.prompts.prompt import PromptTemplate\n"
      ],
      "metadata": {
        "id": "-q51Rgje9tAr"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class pydantci(BaseModel):\n",
        "  platename : str = Field(default_factory=str)\n",
        "  ingradient : List[str] = Field(default_factory=list)"
      ],
      "metadata": {
        "id": "46474uQQ-IAL"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parser  = PydanticOutputParser(pydantic_object=pydantci)\n",
        "\n",
        "format_instructions = parser.get_format_instructions()\n",
        "print(format_instructions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNXwDnyp-TKz",
        "outputId": "08411a8e-6082-438e-c64e-c461d116c5bf"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
            "\n",
            "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}}\n",
            "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
            "\n",
            "Here is the output schema:\n",
            "```\n",
            "{\"properties\": {\"platename\": {\"title\": \"Platename\", \"type\": \"string\"}, \"ingradient\": {\"title\": \"Ingradient\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}}\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = PromptTemplate(input_variables=[\"typee\"],\n",
        "                        template= \"I want to know ingradient of {typee} pasta.\\n{fromat_instructions}\",\n",
        "                        partial_variables={\"fromat_instructions\":format_instructions})\n",
        "\n",
        "\n",
        "print(prompt.format(typee=\"Egyptian\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Dv7w7gn-dDU",
        "outputId": "30b55725-f4e5-4cc6-d717-c5f17a0d7b7f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I want to know ingradient of Egyptian pasta.\n",
            "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
            "\n",
            "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}}\n",
            "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
            "\n",
            "Here is the output schema:\n",
            "```\n",
            "{\"properties\": {\"platename\": {\"title\": \"Platename\", \"type\": \"string\"}, \"ingradient\": {\"title\": \"Ingradient\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}}\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pro = prompt.format(typee=\"Egyptian\")\n",
        "\n",
        "response = llm(pro)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YF6NHl2R-mgP",
        "outputId": "75a01704-7bd2-4112-c513-5e1028f552a6"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"platename\": \"Egyptian Pasta\",\n",
            "  \"ingradient\": [\n",
            "    \"Pasta\",\n",
            "    \"Garlic\",\n",
            "    \"Onion\",\n",
            "    \"Tomato paste\",\n",
            "    \"Spices (such as cumin, coriander, paprika)\",\n",
            "    \"Water\",\n",
            "    \"Vegetable oil\"\n",
            "  ]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output =  parser.parse(response)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXkS7y4T-s4W",
        "outputId": "df7f8521-bce6-482c-d23d-9d38ed1ffd40"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "platename='Egyptian Pasta' ingradient=['Pasta', 'Garlic', 'Onion', 'Tomato paste', 'Spices (such as cumin, coriander, paprika)', 'Water', 'Vegetable oil']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8f47-6bY-yfO",
        "outputId": "d97ee4aa-a73f-4cb1-d1e1-d7c68f21cf4c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "__main__.pydantci"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZEc7qnBj-1by"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}