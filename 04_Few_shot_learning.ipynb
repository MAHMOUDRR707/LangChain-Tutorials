{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Few Shot Learning**\n",
        "is a machine learning framework in which an AI model learns to make accurate predictions by training on a very small number of labeled examples"
      ],
      "metadata": {
        "id": "HBKma5FLK_PT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain==0.0.219 openai==0.27.8\n",
        "\n",
        "# !pip install -q transformers==4.29.2 sentencepiece==0.1.99 accelerate==0.19.0 bitsandbytes==0.39.0\n",
        "\n",
        "!pip install -q python-dotenv==1.0.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7ZFilqjLcRP",
        "outputId": "2abb867b-b862-4a41-f470-abe2f3f11095"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "C7aWyEHOK6BM"
      },
      "outputs": [],
      "source": [
        "from dotenv import dotenv_values\n",
        "env_values = dotenv_values(\"./app.env\")\n",
        "\n",
        "openai_api_key = env_values['OPEN_API_KEY']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "from langchain.prompts.prompt import PromptTemplate\n",
        "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.chat_models import ChatOpenAI"
      ],
      "metadata": {
        "id": "Zcp2jhRDLeep"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "\n",
        "llm = OpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.5, openai_api_key=openai_api_key)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TcG4sEqIO4tK",
        "outputId": "e92406d3-7ef6-4104-e08a-07edced1cd9d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain/llms/openai.py:189: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/llms/openai.py:769: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "demo_message = \"\"\"\n",
        "Country Name: Egypt | Capital Name: Cairo\n",
        "Country Name: Saudi Arabia | Capital Name: Riyadh\n",
        "Country Name: France | Capital Name: Paris\n",
        "Country Name: China |\n",
        "\"\"\".strip()\n",
        "\n",
        "print( llm( demo_message ) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlhCeFjTO5Gi",
        "outputId": "c407aa6a-7cad-43db-8052-057501f60bf5"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Capital Name: Beijing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "demo_template = PromptTemplate(\n",
        "    template=\"Country Name: {country} | Capital Name: {capital}\",\n",
        "    input_variables=['country', 'capital']\n",
        ")\n",
        "\n",
        "examples = [\n",
        "    {\"country\": \"Egypt\", \"capital\": \"Cairo\"},\n",
        "    {\"country\": \"Saudi Arabia\", \"capital\": \"Riyadh\"},\n",
        "    {\"country\": \"France\", \"capital\": \"Paris\"},\n",
        "]\n",
        "\n",
        "prompt = FewShotPromptTemplate(\n",
        "    examples=examples,\n",
        "    example_prompt=demo_template,\n",
        "    suffix=\"Country Name: {country} |\",\n",
        "    input_variables=['country']\n",
        ")"
      ],
      "metadata": {
        "id": "MaSw_bU4Ritt"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print( llm( prompt.format(country='Germany') ) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_baqg-SO7-R",
        "outputId": "c7d4e7e9-42ac-4588-b9d9-22250830a2dd"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Capital Name: Berlin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Riddles"
      ],
      "metadata": {
        "id": "tpwuQlVumOaI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "riddle_1 = \"\"\"\n",
        "I have five oranges, and the sum of what my sister and brother have is three times what I have plus thirty-five\n",
        "\"\"\".strip()\n",
        "\n",
        "print( llm( riddle_1 ) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hxckc2IOjXLq",
        "outputId": "bbf27a86-070f-4740-82af-18c27266b051"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Let's represent what you have as x.\n",
            "\n",
            "You have 5 oranges, so x = 5.\n",
            "\n",
            "The sum of what your sister and brother have is three times what you have plus thirty-five, so the total number of oranges they have is 3x + 35.\n",
            "\n",
            "Let's substitute x = 5 into the equation:\n",
            "\n",
            "3(5) + 35 = 15 + 35 = 50\n",
            "\n",
            "Therefore, your sister and brother have a total of 50 oranges.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "riddle_3 = \"\"\"\n",
        "When I was seven, my sister was twice my age. Now I am seventy years old, how old can my sister be?\n",
        "\"\"\".strip()\n",
        "\n",
        "print( llm( riddle_3 ) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NxOUGaMmSLz",
        "outputId": "97469f8e-6fb7-49ea-9fbd-412aff41e126"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "If your sister was twice your age when you were seven, that means she was 14 at that time. Since then, 63 years have passed (70 - 7 = 63), so your sister would be 77 years old now.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "examples = [\n",
        "    {\n",
        "        \"question\": \"When I was seven, my sister was twice my age. Now I am seventy years old, how old can my sister be?\",\n",
        "        \"answer\": \"\\n\".join([\n",
        "            \"We will followup some questions to get the answer.\",\n",
        "            \"Follow up: How old was your sister when you were seven?\",\n",
        "            \"Intermediate answer: Twice, which mean 14 years.\",\n",
        "            \"Follow up: What is the difference between your age and your sister's age?\",\n",
        "            \"Intermediate answer: 14 years - 7 years = 7 years.\",\n",
        "            \"Follow up: When you were seventy years old, how old would your sister be?\",\n",
        "            \"Intermediate answer: my age (70) +  The difference between me and my sister's age (7) = 77 years.\",\n",
        "            \"Final Answer: 77 years.\"\n",
        "        ])\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"I have five oranges, and the sum of what my sister and brother have is three times what I have plus thirty-five?\",\n",
        "        \"answer\": \"\\n\".join([\n",
        "            \"We will followup some questions to get the answer.\",\n",
        "            \"Follow up: How many oranges do you have?\",\n",
        "            \"Intermediate answer: 5 oranges.\",\n",
        "            \"Follow up: How many oranges does your sister and brother have?\",\n",
        "            \"Intermediate answer: three times: = 3 * 5 = 15. Also, we need to add thirty-five to them: 15 + 35 = 50 \",\n",
        "            \"Final Answer: 50 oranges.\"\n",
        "        ])\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "RWiiXUy9mXrK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_prompt = PromptTemplate(input_variables=[\"question\", \"answer\"], template=\"Question: {question}\\n{answer}\")\n",
        "\n",
        "prompt = FewShotPromptTemplate(\n",
        "    examples=examples,\n",
        "    example_prompt=example_prompt,\n",
        "    suffix=\"Question: {input}\",\n",
        "    input_variables=[\"input\"]\n",
        ")\n",
        "\n",
        "message = prompt.format(input=\"Total with what my family is 50 oranges. If we subtract one-fifth of the number from them, and add ten more oranges, how many oranges will there be in the end?\")\n",
        "print( llm(message) )"
      ],
      "metadata": {
        "id": "a0qom1btmxz0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AS we could see after update of openAI model the gpt 3.5  could solve equation and solve some tricks like human so no need in  fewshotprompt in this but we add some example of how we do it"
      ],
      "metadata": {
        "id": "EPG1_VIKm1O-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Vvxt8nPanB8W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}